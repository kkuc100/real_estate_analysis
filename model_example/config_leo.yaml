# SageMaker-specific configuration
sagemaker_config:
  instance_type: ml.m5.xlarge                        # Instance type for training
  instance_count: 1                                  # Number of instances for distributed training
  volume_size: 5                                     # EBS volume size in GB
  max_run: 3600                                      # Maximum runtime for training job in seconds
  output_path: s3://sagemaker-us-east-1-025066244931/output  # S3 bucket path for output
  role_arn: arn:aws:iam::025066244931:role/service-role/AmazonSageMaker-ExecutionRole-20240928T193088  # IAM role for SageMaker

# Train test split configuration
train_test_split:
  test_size: 0.33
  random_state: 42

# Configuration for the XGBoost Regressor
hyperparameters:
  # General parameters
  n_rounds: 600                   # Number of trees in the ensemble
  learning_rate: 0.1                  # Step size shrinkage
  max_depth: 1                        # Maximum depth of trees
  min_child_weight: 1                 # Minimum sum of instance weights in a child
  gamma: 0                            # Minimum loss reduction to make a further partition
  subsample: 0.8                      # Fraction of samples to use for each tree
  colsample_bytree: 0.8               # Fraction of features to use for each tree
  colsample_bylevel: 1                # Subsample ratio of columns for each split in each level
  colsample_bynode: 1                 # Subsample ratio of columns for each split in each node
  
  # Learning objective and metrics
  objective: 'reg:squarederror'       # Regression objective
  eval_metric: 'rmse'                 # Evaluation metric for regression (Root Mean Squared Error)
  base_score: 0.5                     # Initial prediction score for all instances
  
  # Tree construction options
  tree_method: 'auto'                 # Tree construction algorithm
  booster: 'gbtree'                   # The booster to use
  grow_policy: 'depthwise'            # Growth policy for the tree
  
  # Regularization parameters
  alpha: 0.1                          # L1 regularization term on weights
  lambda: 1                           # L2 regularization term on weights
  
  # Other parameters
  n_jobs: 4                           # Number of parallel threads used to run XGBoost
  random_state: 42                    # Seed for reproducibility
  verbosity: 1                        # Verbosity of messages
  max_bin: 256                        # Maximum number of discrete bins for histogram-based algorithms
  enable_categorical: false           # Enable categorical features support